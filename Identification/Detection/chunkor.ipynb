{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "622ea926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "parent = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, parent)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Helpers import loadData, multiplot, sphereMask, dataSizes, chunkor\n",
    "importlib.reload(sys.modules['Helpers.chunkor'])\n",
    "importlib.reload(sys.modules['Helpers.dataSizes'])\n",
    "importlib.reload(sys.modules['Helpers'])\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6964280",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderData = os.path.join(os.path.dirname(parent),'Data')\n",
    "data = loadData(location=folderData, fileName='downscale_17.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "706c6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = sphereMask(diameter=100,pad=2,scale=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce13e6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desktop device detected: NVIDIA RTX A2000 12GB\n",
      "Data Ram: 0.21 GB\n",
      "Attempting 4 partitions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VRam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reserved</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allocated</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            VRam\n",
       "Total      11.99\n",
       "Reserved    0.00\n",
       "Allocated   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stuff = chunkor(data,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb964d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.get_device_name()\n",
    "if device == 'NVIDIA RTX A2000 12GB':\n",
    "    client = 'Desktop'\n",
    "    cuts = 2\n",
    "elif device == 'NVIDIA RTX 4000 Ada Generation':\n",
    "    client = 'Server'\n",
    "    cuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abe4582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desktop device detected: NVIDIA RTX A2000 12GB\n",
      "Data Ram: 0.21 GB\n",
      "Attempting 4 partitions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VRam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reserved</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allocated</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            VRam\n",
       "Total      11.99\n",
       "Reserved    0.00\n",
       "Allocated   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = [torch.cuda.get_device_properties(0).total_memory,\n",
    "        torch.cuda.memory_reserved(0),\n",
    "        torch.cuda.memory_allocated(0)]\n",
    "\n",
    "df = pd.DataFrame([np.round(item/(1024**3),2) for item in info],\n",
    "                   index=['Total','Reserved','Allocated'],columns=['VRam'])\n",
    "\n",
    "print(f'{client} device detected: {device}')\n",
    "print(f'Data Ram: {np.round(data.nbytes/(1024**3),2)} GB')\n",
    "print(f'Attempting {2**cuts} partitions')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58ffc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(chunk)\n\u001b[0;32m     20\u001b[0m     pchunks\u001b[38;5;241m.\u001b[39mappend(F\u001b[38;5;241m.\u001b[39mpad(chunk,pad\u001b[38;5;241m=\u001b[39m(pads,)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpchunks\u001b[49m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYuh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "r,c,z = data.shape\n",
    "pads = int(kernel.shape[0]/2)\n",
    "\n",
    "lower = data[:,:,0:int(z/2)+pads] # Lower Half\n",
    "upper = data[:,:,int(z/2)-pads:z] # Upper Half\n",
    "\n",
    "if cuts==1:\n",
    "    chunks = [lower,upper]\n",
    "elif cuts == 2:\n",
    "    chunks = [lower[:,0:int(c/2)+pads,:],\n",
    "              lower[:,int(c/2)-pads:c,:],\n",
    "              upper[:,0:int(c/2)+pads,:],\n",
    "              upper[:,int(c/2)-pads:c,:]]\n",
    "\n",
    "pchunks = [F.pad(torch.from_numpy(chunk), pad=(pads,)*6) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### End of modern era\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7fad80f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desktop device detected: NVIDIA RTX A2000 12GB\n",
      "Data Ram: 0.21 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VRam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reserved</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allocated</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            VRam\n",
       "Total      11.99\n",
       "Reserved    0.00\n",
       "Allocated   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.cuda.get_device_name()\n",
    "desktopGPU = 'NVIDIA RTX A2000 12GB'\n",
    "serverGPU = 'NVIDIA RTX 4000 Ada Generation'\n",
    "\n",
    "if device == desktopGPU:\n",
    "    client = 'Desktop'\n",
    "    cuts = 2\n",
    "elif device == serverGPU:\n",
    "    client = 'Server'\n",
    "    cuts = 1\n",
    "\n",
    "netVram = torch.cuda.get_device_properties(0).total_memory\n",
    "resVram = torch.cuda.memory_reserved(0)\n",
    "aloVram = torch.cuda.memory_allocated(0)\n",
    "info = [netVram,resVram,aloVram]\n",
    "\n",
    "df = pd.DataFrame([np.round(item/(1024**3),2) for item in info],\n",
    "                  index=['Total','Reserved','Allocated'],columns=['VRam'])\n",
    "\n",
    "print(f'{client} device detected: {device}')\n",
    "print(f'Data Ram: {np.round(data.nbytes/(1024**3),2)} GB')\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d26233",
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c,z = data.shape\n",
    "kernel = sphereMask(diameter=100,pad=2,scale=.6)\n",
    "pad = int(kernel.shape[0]/2)\n",
    "\n",
    "lower = data[:,:,0:int(z/2)+pad] # Lower Half\n",
    "upper = data[:,:,int(z/2)-pad:z] # Upper Half\n",
    "\n",
    "if cuts==1:\n",
    "    chunks = [lower,upper]\n",
    "elif cuts == 2:\n",
    "    chunks = [lower[:,0:int(c/2)+pad,:],\n",
    "              lower[:,int(c/2)-pad:c,:],\n",
    "              upper[:,0:int(c/2)+pad,:],\n",
    "              upper[:,int(c/2)-pad:c,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b65570c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Helpers' from 'c:\\\\Users\\\\Lab User\\\\Desktop\\\\temp1\\\\Granular-Compression\\\\Identification\\\\Helpers\\\\__init__.py'>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "parent = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, parent)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Helpers import loadData, multiplot, sphereMask, dataSizes, chunkor\n",
    "importlib.reload(sys.modules['Helpers.sphereMask'])\n",
    "importlib.reload(sys.modules['Helpers.chunkor'])\n",
    "importlib.reload(sys.modules['Helpers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7507544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desktop device detected: NVIDIA RTX A2000 12GB\n",
      "Data Ram: 0.21 GB\n",
      "Attempting 4 partitions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VRam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reserved</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allocated</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            VRam\n",
       "Total      11.99\n",
       "Reserved    0.00\n",
       "Allocated   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunks = chunkor(data,kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
