{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1298c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "cur=os.getcwd()\n",
    "paths = [cur := os.path.dirname(cur) for _ in range(3)]\n",
    "sys.path.insert(0, paths[0])\n",
    "from Helpers import loadData, sphereMask, saveData, visualizer\n",
    "importlib.reload(sys.modules['Helpers'])\n",
    "importlib.reload(sys.modules['Helpers.visualizer'])\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.feature import peak_local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48da6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish variable conditions\n",
    "diameter=100\n",
    "width=1.3\n",
    "Cutoff=5\n",
    "MinSep=5\n",
    "\n",
    "highHist=250\n",
    "lowHist=10\n",
    "\n",
    "maxDwTicker=10\n",
    "mindeldiameter=.0001\n",
    "\n",
    "maxTicker=10\n",
    "mindelchi2=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7a527b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "dataFolder = os.path.join(paths[1],'Data')\n",
    "oldData = loadData(dataFolder, 'downscale_17.hdf5')\n",
    "data = loadData(dataFolder, 'convMap_17.hdf5')\n",
    "\n",
    "# Find peaks\n",
    "peaks = peak_local_max(data, min_distance=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "343e0d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_particle_grid(peak_x_positions, peak_y_positions, grid_width, grid_height, \n",
    "                        boundary_rect, num_peaks, kernel_padding_size, use_radius):\n",
    "    \"\"\"\n",
    "    Create a local grid centered on each particle and an overlap matrix for Voronoi volumes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    peak_x_positions : array-like\n",
    "        X coordinates of peak positions\n",
    "    peak_y_positions : array-like\n",
    "        Y coordinates of peak positions\n",
    "    grid_width : int\n",
    "        Width of the grid (x dimension)\n",
    "    grid_height : int\n",
    "        Height of the grid (y dimension)\n",
    "    boundary_rect : array-like\n",
    "        Rectangle boundaries [y_min, y_max, x_min, x_max]\n",
    "    num_peaks : int\n",
    "        Number of peaks/particles\n",
    "    kernel_padding_size : float\n",
    "        Size of the kernel padding region\n",
    "    use_radius : bool\n",
    "        If True, use absolute distance; if False, use complex distance\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    particle_grid : ndarray\n",
    "        Complex grid (cx + i*cy) centered on each particle\n",
    "    overlap_map : ndarray\n",
    "        Image showing which particle (1-indexed) owns each pixel in its Voronoi region\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    Creates a local grid for the Voronoi volume of each particle.\n",
    "    The union of all grids covers the entire image within the boundary rectangle.\n",
    "    Maximum individual grid size is 2*ceil(kernel_padding_size/2).\n",
    "    \n",
    "    Revision history:\n",
    "    01/16/01 Mark D. Shattuck <mds> calcimg.m\n",
    "    02/30/06 mds rename pgrid.m return peakGrid and overlap instead of ci\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle empty input\n",
    "    if len(peak_x_positions) == 0:\n",
    "        particle_grid = np.zeros((grid_width, grid_height), dtype=complex)\n",
    "        overlap_map = np.zeros((grid_width, grid_height))\n",
    "        return particle_grid, overlap_map\n",
    "    \n",
    "    # Extract boundary coordinates\n",
    "    y_min = boundary_rect[0]\n",
    "    y_max = boundary_rect[1]\n",
    "    x_min = boundary_rect[2]\n",
    "    x_max = boundary_rect[3]\n",
    "    \n",
    "    # Create coordinate meshgrids (1-indexed to match MATLAB convention)\n",
    "    x_coords, y_coords = np.meshgrid(\n",
    "        np.arange(1, grid_width + 1), \n",
    "        np.arange(1, grid_height + 1), \n",
    "        indexing='ij'\n",
    "    )\n",
    "    \n",
    "    # Initialize particle grid with large values\n",
    "    max_dimension = max(grid_width, grid_height)\n",
    "    particle_grid = np.ones((grid_width, grid_height), dtype=complex) * max_dimension\n",
    "    \n",
    "    # Initialize overlap map (tracks which particle owns each pixel)\n",
    "    overlap_map = np.zeros((grid_width, grid_height))\n",
    "    \n",
    "    # Define kernel range (region around each particle to check)\n",
    "    half_kernel = int(np.ceil(kernel_padding_size / 2))\n",
    "    kernel_offset_x = np.arange(-half_kernel, half_kernel + 1)\n",
    "    kernel_offset_y = kernel_offset_x.copy()\n",
    "    \n",
    "    # Process each particle/peak\n",
    "    for particle_idx in range(num_peaks):\n",
    "        # Calculate extended kernel range around this particle\n",
    "        kernel_range_x = np.round(peak_x_positions[particle_idx]) + kernel_offset_x\n",
    "        kernel_range_y = np.round(peak_y_positions[particle_idx]) + kernel_offset_y\n",
    "        \n",
    "        # Clip to boundary rectangle\n",
    "        valid_x = kernel_range_x[(kernel_range_x <= x_max) & (kernel_range_x >= x_min)].astype(int)\n",
    "        valid_y = kernel_range_y[(kernel_range_y <= y_max) & (kernel_range_y >= y_min)].astype(int)\n",
    "        \n",
    "        # Only process if particle influence is inside boundary\n",
    "        if valid_x.size > 0 and valid_y.size > 0:\n",
    "            # Convert to 0-based indices for NumPy\n",
    "            valid_x_idx = valid_x - 1\n",
    "            valid_y_idx = valid_y - 1\n",
    "            \n",
    "            # Calculate distance from particle to each grid point in the region\n",
    "            delta_x = x_coords[np.ix_(valid_x_idx, valid_y_idx)] - peak_x_positions[particle_idx]\n",
    "            delta_y = y_coords[np.ix_(valid_x_idx, valid_y_idx)] - peak_y_positions[particle_idx]\n",
    "            \n",
    "            if use_radius:\n",
    "                # Use absolute distance (Euclidean)\n",
    "                distance_grid = np.abs(delta_x + 1j * delta_y)\n",
    "                \n",
    "                # Find pixels where this particle is closer than current assignment\n",
    "                closer_mask = particle_grid[np.ix_(valid_x_idx, valid_y_idx)] >= distance_grid\n",
    "                closer_x, closer_y = np.where(closer_mask)\n",
    "                \n",
    "                # Update overlap map and particle grid for closer pixels\n",
    "                for i, j in zip(closer_x, closer_y):\n",
    "                    overlap_map[valid_x_idx[i], valid_y_idx[j]] = particle_idx + 1  # 1-indexed\n",
    "                    particle_grid[valid_x_idx[i], valid_y_idx[j]] = distance_grid[i, j]\n",
    "                    \n",
    "            else:\n",
    "                # Use complex distance (preserves direction)\n",
    "                distance_grid = delta_x + 1j * delta_y\n",
    "                \n",
    "                # Find pixels where this particle is closer than current assignment\n",
    "                closer_mask = np.abs(particle_grid[np.ix_(valid_x_idx, valid_y_idx)]) >= np.abs(distance_grid)\n",
    "                closer_x, closer_y = np.where(closer_mask)\n",
    "                \n",
    "                # Update overlap map and particle grid for closer pixels\n",
    "                for i, j in zip(closer_x, closer_y):\n",
    "                    overlap_map[valid_x_idx[i], valid_y_idx[j]] = particle_idx + 1  # 1-indexed\n",
    "                    particle_grid[valid_x_idx[i], valid_y_idx[j]] = distance_grid[i, j]\n",
    "    \n",
    "    return particle_grid, overlap_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f230efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ideal_particle_image(radial_grid, diameter, width):\n",
    "    \"\"\"\n",
    "    Calculate ideal particle image with smooth edge falloff.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    radial_grid : ndarray\n",
    "        Grid of radial distances from particle center\n",
    "    diameter : float\n",
    "        Diameter of the particle\n",
    "    width : float\n",
    "        Width parameter controlling edge sharpness.\n",
    "        2*width represents the distance over which 76% of the intensity falloff occurs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ideal_particle_image : ndarray\n",
    "        Image of ideal particle with values from 0 (far from particle) to 1 (center)\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    Uses hyperbolic tangent (tanh) for smooth transition from particle to background.\n",
    "    The transition is centered at diameter/2 and controlled by the width parameter.\n",
    "    \n",
    "    Revision history:\n",
    "    08/04/05 Mark D. Shattuck <mds> ipf.m\n",
    "    01/30/06 mds added abs(radialGrid)\n",
    "    04/30/07 mds made w a true measure of width\n",
    "    \"\"\"\n",
    "    # Calculate normalized distance from particle edge\n",
    "    distance_from_edge = (np.abs(radial_grid) - diameter/2) / width\n",
    "    \n",
    "    # Create smooth falloff using tanh: 1 at center, 0 far from particle\n",
    "    ideal_particle_image = (1 - np.tanh(distance_from_edge)) / 2\n",
    "    \n",
    "    return ideal_particle_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fec7feec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m peak_y_locations \u001b[38;5;241m=\u001b[39m peaks[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Get image dimensions\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m grid_width, grid_height \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create local grid centered on each particle and overlap matrix\u001b[39;00m\n\u001b[0;32m     17\u001b[0m peak_grids, overlap_map \u001b[38;5;241m=\u001b[39m create_particle_grid(\n\u001b[0;32m     18\u001b[0m     peak_x_locations \u001b[38;5;241m-\u001b[39m half_kernel_size, \n\u001b[0;32m     19\u001b[0m     peak_y_locations \u001b[38;5;241m-\u001b[39m half_kernel_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Setup for ideal particle\n",
    "kernel_size = 2 * int(diameter/2 + 4*width/2) - 1  # size of ideal particle image\n",
    "half_kernel_size = (kernel_size - 1) / 2            # (size-1)/2 of ideal particle image\n",
    "coord_range = np.arange(-half_kernel_size, half_kernel_size + 1)\n",
    "x_grid, y_grid = np.meshgrid(coord_range, coord_range, indexing='ij')  # ideal particle image grid\n",
    "radial_grid = np.hypot(x_grid, y_grid)              # radial coordinate\n",
    "\n",
    "# Extract peak locations\n",
    "num_peaks = len(peaks)\n",
    "peak_x_locations = peaks[:, 0]  # Assuming peaks is Nx2 array\n",
    "peak_y_locations = peaks[:, 1]\n",
    "\n",
    "# Get image dimensions\n",
    "grid_width, grid_height = data.shape\n",
    "\n",
    "# Create local grid centered on each particle and overlap matrix\n",
    "peak_grids, overlap_map = create_particle_grid(\n",
    "    peak_x_locations - half_kernel_size, \n",
    "    peak_y_locations - half_kernel_size,\n",
    "    grid_width, \n",
    "    grid_height,\n",
    "    [1, grid_width, 1, grid_height], \n",
    "    num_peaks, \n",
    "    2 * half_kernel_size + 3, \n",
    "    0\n",
    ")\n",
    "\n",
    "# Create ideal particle kernels\n",
    "peak_kernels = create_ideal_particle_image(peak_grids, diameter, width)\n",
    "\n",
    "# Calculate residuals and chi-squared\n",
    "residuals = peak_kernels - data  # Calculate difference image\n",
    "chi_squared = np.sum(residuals**2)  # Calculate Chi-Squared\n",
    "print(f'Chi-Squared={chi_squared}')\n",
    "\n",
    "# Save for later optimized comparison\n",
    "chi_squared_initial = chi_squared\n",
    "residuals_initial = residuals.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_diameter_width(peak_grids, residuals, diameter, width):\n",
    "    \"\"\"\n",
    "    Calculate one Newton's step toward minimizing residuals^2 over diameter and width.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    peak_grids : ndarray\n",
    "        Grid of distances from particle centers\n",
    "    residuals : ndarray\n",
    "        Difference between model and actual image\n",
    "    diameter : float\n",
    "        Current particle diameter estimate\n",
    "    width : float\n",
    "        Current width parameter estimate\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    del_diameter : float\n",
    "        Change in diameter to minimize residuals\n",
    "    del_width : float\n",
    "        Change in width to minimize residuals\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    Uses Newton's method with approximate Hessian to find parameter updates.\n",
    "    \n",
    "    Revision history:\n",
    "    09/14/00 Mark D. Shattuck <mds> cidDw.m\n",
    "    04/30/07 mds changed meaning of width to 1/width\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create general params\n",
    "    particle_kern = peak_grids - diameter/2\n",
    "    inv_width = 1/width\n",
    "    hessian = np.zeros((2, 2))\n",
    "    \n",
    "    # Create starter functions\n",
    "    tanh_term = np.tanh(particle_kern * inv_width)\n",
    "    sech2_term = (1 / np.cosh(particle_kern * inv_width))**2\n",
    "    \n",
    "    # First partial derivatives\n",
    "    dip_dD = inv_width * sech2_term / 4\n",
    "    dip_dw = -particle_kern/2 * sech2_term\n",
    "    \n",
    "    # Second partial derivatives\n",
    "    dip_DD = inv_width**2 / 4 * tanh_term * sech2_term\n",
    "    dip_ww = particle_kern**2 * tanh_term * sech2_term\n",
    "    dip_Dw = sech2_term * (1 - 2*inv_width * particle_kern * tanh_term) / 4\n",
    "    \n",
    "    # Gradient of \"cost function\"\n",
    "    chi_D = residuals * dip_dD\n",
    "    chi_w = residuals * dip_dw\n",
    "    \n",
    "    # Approximate Hessian of \"cost function\"\n",
    "    chi_DD = dip_dD**2 + residuals * dip_DD\n",
    "    chi_ww = dip_dw**2 + residuals * dip_ww\n",
    "    chi_Dw = dip_dD * dip_dw + residuals * dip_Dw\n",
    "    \n",
    "    # Fill out approximate Hessian\n",
    "    delta_arr = np.array([np.sum(chi_D), np.sum(chi_w)])\n",
    "    hessian[0, 0] = np.sum(chi_DD)\n",
    "    hessian[0, 1] = np.sum(chi_Dw)\n",
    "    hessian[1, 0] = hessian[0, 1]\n",
    "    hessian[1, 1] = np.sum(chi_ww)\n",
    "    \n",
    "    # Solve for parameter updates using pseudoinverse\n",
    "    del_Dw = -delta_arr @ np.linalg.pinv(hessian)\n",
    "    del_diameter = del_Dw[0]\n",
    "    del_width = -inv_width * del_Dw[1] / (inv_width + del_Dw[1])\n",
    "    \n",
    "    return del_diameter, del_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff7f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best diameter and width\n",
    "ticker = 0\n",
    "del_diameter = 1e99\n",
    "\n",
    "# Optimize D and w\n",
    "while (abs(del_diameter) > min_del_diameter) and (ticker < max_dw_ticker):\n",
    "    \n",
    "    # Run Newton's method for updated diameters and widths\n",
    "    del_diameter, del_width = optimize_diameter_width(\n",
    "        np.abs(peak_grids), \n",
    "        residuals, \n",
    "        diameter, \n",
    "        width\n",
    "    )\n",
    "    diameter = diameter + del_diameter\n",
    "    width = width + del_width\n",
    "    \n",
    "    # Create kernels with new better diameters and widths, then find residuals\n",
    "    peak_kernels = create_ideal_particle_image(np.abs(peak_grids), diameter, width)\n",
    "    residuals = peak_kernels - data\n",
    "    \n",
    "    # Iterate\n",
    "    print('.', end='', flush=True)\n",
    "    ticker += 1\n",
    "\n",
    "# Print optimization stats\n",
    "print()  # newline\n",
    "chi_squared = np.sum(residuals**2)\n",
    "print(f'Chi-Squared={chi_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_particle_positions(particle_grids, overlap, residuals, num_particles, diameter, width):\n",
    "    \"\"\"\n",
    "    Calculate one Newton's step toward minimizing residuals^2 over particle centers.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    particle_grids : ndarray\n",
    "        Complex grid (cx + i*cy) centered on each particle\n",
    "    overlap : ndarray\n",
    "        Image showing which particle owns each pixel\n",
    "    residuals : ndarray\n",
    "        Difference between model and actual image\n",
    "    num_particles : int\n",
    "        Number of particles\n",
    "    diameter : float\n",
    "        Particle diameter\n",
    "    width : float\n",
    "        Width parameter\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dx_positions : ndarray\n",
    "        Change in x positions for each particle\n",
    "    dy_positions : ndarray\n",
    "        Change in y positions for each particle\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    Uses Newton's method with Hessian to find position updates.\n",
    "    Movement is limited to maxdr=20 pixels per step.\n",
    "    \n",
    "    Revision history:\n",
    "    09/14/00 Mark D. Shattuck <mds> cidp2.m\n",
    "    02/15/02 mds implement over and separate calc per particle\n",
    "    06/25/04 mds limit change to maxdr=2\n",
    "    04/30/07 mds changed meaning of w to 1/w\n",
    "    \"\"\"\n",
    "    \n",
    "    inv_width = 1 / width  # w is real width\n",
    "    max_dr = 20  # max change per step\n",
    "    \n",
    "    hessian = np.zeros((2, 2))\n",
    "    position_changes = np.zeros((num_particles, 2))\n",
    "    \n",
    "    # Create list of pixels for each particle\n",
    "    flat_overlap = overlap.flatten()\n",
    "    sorted_indices = np.argsort(flat_overlap)\n",
    "    particle_counts = np.bincount(flat_overlap.astype(int), minlength=num_particles + 1)\n",
    "    cumulative_counts = np.cumsum(particle_counts)\n",
    "    \n",
    "    # Useful numbers\n",
    "    radial_distance = np.abs(particle_grids) + np.finfo(float).eps\n",
    "    radial_distance_cubed = radial_distance**3 + np.finfo(float).eps\n",
    "    x_component = np.real(particle_grids)\n",
    "    y_component = np.imag(particle_grids)\n",
    "    x_squared = x_component**2\n",
    "    y_squared = y_component**2\n",
    "    \n",
    "    tanh_term = np.tanh((radial_distance - diameter/2) * inv_width)\n",
    "    sech2_term = (1 / np.cosh((radial_distance - diameter/2) * inv_width))**2\n",
    "    \n",
    "    # First derivatives\n",
    "    dip_dx = -inv_width * x_component * sech2_term / 2 / radial_distance\n",
    "    dip_dy = -inv_width * y_component * sech2_term / 2 / radial_distance\n",
    "    \n",
    "    # Second derivatives\n",
    "    dip_dxx = inv_width * sech2_term * (2*inv_width*x_squared*radial_distance*tanh_term - y_squared) / 2 / radial_distance_cubed\n",
    "    dip_dyy = inv_width * sech2_term * (2*inv_width*y_squared*radial_distance*tanh_term - x_squared) / 2 / radial_distance_cubed\n",
    "    dip_dxy = inv_width * x_component * y_component * sech2_term * (2*inv_width*radial_distance*tanh_term + 1) / 2 / radial_distance_cubed\n",
    "    \n",
    "    # Gradient components\n",
    "    chi_x = residuals * dip_dx\n",
    "    chi_y = residuals * dip_dy\n",
    "    \n",
    "    # Hessian components\n",
    "    chi_xx = dip_dx**2 + residuals * dip_dxx\n",
    "    chi_yy = dip_dy**2 + residuals * dip_dyy\n",
    "    chi_xy = dip_dx * dip_dy + residuals * dip_dxy\n",
    "    \n",
    "    # Flatten arrays for indexing\n",
    "    chi_x_flat = chi_x.flatten()\n",
    "    chi_y_flat = chi_y.flatten()\n",
    "    chi_xx_flat = chi_xx.flatten()\n",
    "    chi_yy_flat = chi_yy.flatten()\n",
    "    chi_xy_flat = chi_xy.flatten()\n",
    "    \n",
    "    # Loop over particles\n",
    "    for particle_idx in range(num_particles):\n",
    "        # Get indices for this particle's pixels\n",
    "        start_idx = cumulative_counts[particle_idx]\n",
    "        end_idx = cumulative_counts[particle_idx + 1]\n",
    "        pixel_indices = sorted_indices[start_idx:end_idx]\n",
    "        \n",
    "        # Build gradient vector\n",
    "        gradient = np.array([\n",
    "            np.sum(chi_x_flat[pixel_indices]),\n",
    "            np.sum(chi_y_flat[pixel_indices])\n",
    "        ])\n",
    "        \n",
    "        # Build Hessian matrix\n",
    "        hessian[0, 0] = np.sum(chi_xx_flat[pixel_indices])\n",
    "        hessian[0, 1] = np.sum(chi_xy_flat[pixel_indices])\n",
    "        hessian[1, 0] = hessian[0, 1]\n",
    "        hessian[1, 1] = np.sum(chi_yy_flat[pixel_indices])\n",
    "        \n",
    "        # Newton's step\n",
    "        position_changes[particle_idx, :] = gradient @ np.linalg.pinv(hessian)\n",
    "    \n",
    "    dx_positions = position_changes[:, 0]\n",
    "    dy_positions = position_changes[:, 1]\n",
    "    \n",
    "    # Limit step size to max_dr\n",
    "    position_change_magnitude = np.sqrt(dx_positions**2 + dy_positions**2)\n",
    "    large_step_mask = position_change_magnitude > max_dr\n",
    "    dx_positions[large_step_mask] = dx_positions[large_step_mask] / position_change_magnitude[large_step_mask]\n",
    "    dy_positions[large_step_mask] = dy_positions[large_step_mask] / position_change_magnitude[large_step_mask]\n",
    "    \n",
    "    return dx_positions, dy_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best positions\n",
    "ticker = 0\n",
    "del_chi_squared = 1e99\n",
    "\n",
    "# Optimize x, y positions\n",
    "while (abs(del_chi_squared) > min_del_chi_squared) and (ticker < max_ticker):\n",
    "    \n",
    "    # Run Newton's method for updated positions\n",
    "    dx_peak_loc, dy_peak_loc = optimize_particle_positions(\n",
    "        peak_grids, \n",
    "        overlap_map, \n",
    "        residuals, \n",
    "        num_peaks, \n",
    "        diameter, \n",
    "        width\n",
    "    )\n",
    "    peak_x_locations = peak_x_locations + dx_peak_loc\n",
    "    peak_y_locations = peak_y_locations + dy_peak_loc\n",
    "    \n",
    "    # Create new kernels and compute residuals\n",
    "    peak_grids, overlap_map = create_particle_grid(\n",
    "        peak_x_locations - half_kernel_size,\n",
    "        peak_y_locations - half_kernel_size,\n",
    "        grid_width,\n",
    "        grid_height,\n",
    "        [1, grid_width, 1, grid_height],\n",
    "        num_peaks,\n",
    "        2 * half_kernel_size + 3,\n",
    "        0\n",
    "    )\n",
    "    peak_kernels = create_ideal_particle_image(peak_grids, diameter, width)\n",
    "    residuals = peak_kernels - data\n",
    "    \n",
    "    # Calculate the error changes\n",
    "    new_chi_squared = np.sum(residuals**2)\n",
    "    del_chi_squared = chi_squared - new_chi_squared\n",
    "    chi_squared = new_chi_squared\n",
    "    \n",
    "    # Iterate\n",
    "    print('.', end='', flush=True)\n",
    "    ticker += 1\n",
    "\n",
    "# Print optimization stats\n",
    "print()  # newline\n",
    "chi_squared = np.sum(residuals**2)\n",
    "print(f'Chi-Squared={chi_squared}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
